\begin{frame}{TECNICHE DI COMPRESSIONE/OTTIMIZZAZIONE}
    Tecniche di compressione/ottimizzazione utilizzate:
    \begin{enumerate}
        \item {\bfseries{\emph{Pruning}}}\footnotemark[3]: Azzeramento di determinati parametri nella rete;
        \item {\bfseries{\emph{Knowledge Distillation}}}\footnotemark[4]: Trasferimento della "Conoscenza" da un modello di grandi dimensioni, verso un modello pi√π piccolo;
        \item {\bfseries{\emph{Metodologia proposta}}}: combinazione della tecnica di Knowledge Distillation con l'iper-parametro \emph{width-multiplier} $\alpha$ per la derivazione del modello proposto.
    \end{enumerate}
    \footnotetext[3]{\emph{Salama A., "Pruning at a glance: Global neural pruning for model compression", 2019}}
    \footnotetext[4]{\emph{Geoffrey H. et al., "Distilling the Knowledge in a Neural Network", 2015}}
\end{frame}