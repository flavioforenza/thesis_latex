% !TEX encoding = UTF-8
% !TEX TS-program = pdflatex
% !TEX root = ../thesis.tex

%**************************************************************
\chapter{STATO DELL'ARTE}
\label{Capitolo2}
\thispagestyle{empty}

Il tema della guida autonoma si sta sempre più affermando come importante 
oggetto di studio nella comunità scientifica. Visto il grande impiego di sistemi 
basati sul Machine Learning, in particolare le reti neurali, in questa sezione 
verranno introdotti alcuni concetti atti a rappresentare sia la struttura di tali 
sistemi che la loro influenza nell’ambiente automotive. 

\section{Reti Neurali Biologiche}
Il cervello umano ha la capacità di sfruttare la sua struttura di neuroni in modo 
da eseguire più calcoli rispetto a un comune computer. Mediamente ogni cervello 
contiene un numero di neuroni pari a $10^{11}$. La struttura di un neurone biologico 
è quello mostrata in figura (\ref{biological neuron}):
\begin{figure}[H]
    \centering
    \includegraphics[width = 0.6 \linewidth]{images/biological neuron.png}
    \centering
    \caption{Composizione di due neuroni biologici.}
    \label{biological neuron}
\end{figure}
Da come possiamo notare, esistono vari componenti che costituiscono un 
neurone. In particolare, abbiamo i \emph{dendriti} che rappresentano gli ingressi di un 
neurone mentre le uscite sono rappresentare dagli \emph{assoni}. Su ogni assone viaggia 
un impulso elettrico generato dal neurone stesso quando questo si trova in uno 
stato attivo. Ogni neurone è connesso a migliaia di suoi simili ed ogni 
comunicazione fra questi avviene mediante le sinapsi. Quando l’impulso raggiunge 
proprio le sinapsi, questo provoca il rilascio di sostanze chimiche che attraversano 
la giunzioni ed entrano all’interno di altri neuroni. Ci sono due tipologie di sinapsi, 
eccitatori e inibitori. La prima tipologia permette di aumentare la probabilità che 
un neurone si attivi. Tale probabilità è determinata dal peso associato ad ogni 
sinapsi. Avendo multipli collegamenti, ogni neurone effettua una specie di somma 
pesata degli ingressi che, se maggiore di una determinata soglia, può provocare la 
sua attivazione. 

\section{Reti Neurali Artificiali}\label{Reti neurali}
Una rete neurale artificiale è un modello computazionale che, a partire da dei dati 
di input, riesce a produrre un output mediante un meccanismo ispirato a quello 
del cervello umano. Alla base di questa similitudine, tali reti prendono il nome di 
\emph{Artificial Neural Networks (ANN)}. Le prime reti neurali, nate attorno gli anni 
’50, basavano il loro funzionamento sui cosiddetti \emph{percettroni}, neuroni artificiali in 
grado di apprendere e di accumulare esperienza. Ogni rete neurale è composta da 
strati di neuroni, comunemente chiamati \emph{layers}. I dati di input saranno processati 
dai neuroni presenti nell’input layer e da qui, i risultati ottenuti, si propagheranno 
verso i layer nascosti (hidden layers) fino a raggiungere il layer finale di output (Fig. \ref{network structure}).
\begin{figure}[H]
    \centering
    \includegraphics[width = 0.6 \linewidth]{images/netwrok structure.png}
    \centering
    \caption{Struttura di una rete neurale a più livelli.}
    \label{network structure}
\end{figure}
Una componente importante, riguarda la presenza di un insieme di valori 
$w=(w_{j1}, \dots, w_{jm})$ chiamati pesi. Ogni peso è rappresentato da un numero reale 
che riflette il grado di importanza di una data connessione, tra due neuroni, in 
una rete neurale. I pesi possono subire dei cambiamenti in base alla tipologia 
di apprendimento della rete. Una buona configurazione dei pesi riduce l’errore di 
predizione e pertanto migliora l’output del modello. Riprendendo il discorso 
dei neuroni, McCulloch e Pitts  \cite{Chakraverty2019} definirono un modello matematico in grado di 
rappresentarli. In particolare, il compito di ogni singolo neurone è rappresentato 
nella figura (\ref{neural neuron}).
\begin{figure}[H]
    \centering
    \includegraphics[width = \linewidth]{artificial neuron.png}
    \centering
    \caption{Neurone artificiale.}
    \label{neural neuron}
\end{figure}
Da come possiamo notare, un neurone è una semplice funzione non lineare 
che riceve in input una serie di input $X_{ji}$ e produce in output una variabile $y_k$. 
Il calcolo dell’output, di ogni singolo neurone, è composto da una sommatoria 
degli input, di segno positivo o negativo, moltiplicati prima con i corrispettivi 
pesi e successivamente sommati con una variabile, chiamata bias (pregiudizio), 
che corrisponde alla soglia di attivazione del neurone.
\begin{equation}\label{artificial}
    a_j = \sum_{i=0}^m w_{i}x_i + b_i 
\end{equation}
Una soglia è utile per determinare se l’informazione in ingresso “$x$” debba essere 
elaborata oppure scartata. Di solito vi è sempre un input $X_0=1$ che renderebbe 
il bias $ b_i $ uguale uguale al primo peso $W_0$, pertanto la formula (\ref{artificial}) può anche 
essere scritta come:
\begin{equation}\label{artificial without bias}
    a_j = \sum_{i=0}^m w_{i}x_i
\end{equation}
Per poter determinare il valore $y$, dopo aver ottenuto “$a$”, si utilizza una “\emph{funzione 
di attivazione}” non lineare $\varphi(\cdot)$:
\begin{equation}\label{activation function 1}
    y_j = \varphi(a) = \varphi\left(\sum_{i=0}^m w_ix_i\right)
\end{equation}
L’uscita $y$ determinerà l’attivazione del prossimo neurone. Se il valore ricevuto è 
maggiore di zero, allora il neurone si attiverà, altrimenti resterà spento.
\begin{equation}\label{activation function 2}
    y_j = \left\{
        \begin{array}{rl}
        1 & \mbox{if } a_j \geq 0 \\
        0 & \mbox{if } a_j < 0
        \end{array}
        \right.
\end{equation}
Esistono varie funzioni di attivazione, diverse sono elencate in figura (\ref{activation functions}).
\begin{figure}[H]
    \centering
    \includegraphics[width = \linewidth]{activation functions.png}
    \centering
    \caption{Varie funzioni di attivazione.}
    \label{activation functions}
\end{figure}
Grazie a questa massiccia interconnessione, le reti neurali artificiali sono in 
grado non solo di imitare il comportamento del cervello umano ma anche di 
svolgere diversi compiti grazie a una opportuna fase di apprendimento. 

\section{Algoritmi di apprendimento}
Lo scambio di dati tra i vari neuroni consente alla rete neurale di poter generalizzare 
anche con dati mai visti nel training set. Questo processo prende il nome di 
“\emph{Apprendimento}”. L’apprendimento di un modello di rete è tipicamente effettuato 
a partire da un insieme di dati di addestramento chiamato training test. All’interno 
di questi insiemi abbiamo la presenza di esempi formati da coppie $(x^j, y^j)$, con 
$j=1,…,n$, dove $y^j$ sta a rappresentare il valore di output desiderato in funzione 
del dato di input $x^j$. Per ricavare il valore target è necessario ricercare gli 
opportuni valori dei pesi, indispensabili a minimizzare l’errore commesso. La 
quantità dell’errore commesso, dal singolo neurone $j$, è esprimibile mediante (\ref{error function}):
\begin{equation}\label{error function 1}
    \emph{$e_j$}=(\hat{y}_j-y_j)^2
\end{equation}
Si può osservare che il calcolo di (\ref{error function 1}) è riconducibile alla somma dei quadrati 
residua tra il valore stimato $\hat{y}_j$ e quello desiderato $y_j$. L’errore totale derivato da 
tutta la rete è calcolabile prendendo in considerazione la \emph{Funzione di Errore}, a 
volte chiamata anche di \emph{Costo}, esprimibile dal calcolo della seguente formula:
\begin{equation}\label{error function}
    \emph{$E$}=\frac{1}{2}\sum_{j=1}^me_j
\end{equation}
dove $m$ rappresenta il numero totale di neuroni presenti nell’output layer.
La funzione di errore $E$ risulta essere molto importate nella fase di apprendimento in quanto misura la distanza 
dalla soluzione ottimale. In generale, la funzione di errore ha diversi minimi (Fig. \ref{minimum and maximum})
\begin{figure}[H]
    \centering
    \includegraphics[width = 0.7\linewidth]{cost-function.png}
    \centering
    \caption{Esempio di minimo globale ($w^A$) e locale ($w^B$).}
    \label{minimum and maximum}
\end{figure}
Per ottenere un valore della funzione relativamente basso, l’obiettivo è racchiuso 
nella ricerca del minimo globale. Tale ricerca avviene in maniera iterativa, partendo 
da dei pesi a valori casuali, fino a definirne dei valori fissi. La ricerca dei pesi 
ottimali avviene mediante calcolo delle derivate parziali sulla funzione di errore, 
ovvero del suo vettore gradiente $\nabla{E}$ (\ref{gradient vector}). 
\begin{equation}\label{gradient vector}
    \nabla{E}[\vec{w}]\equiv\left[\frac{\partial E}{\partial w_{0}}, \frac{\partial E}{\partial w_{1}}, \dots, \frac{\partial E}{\partial w_{j}}\right]
\end{equation}
Questo vettore è utile a definire la direzione ed il verso della funzione di errore, 
in base al set di pesi considerato. Il calcolo delle derivate viene svolto da una ben 
nota tecnica presente allo stato dell'arte, chiamata \emph{Back Propagation} (discussa 
nella sezione \ref{BP} di questo elaborato). Una rete neurale artificiale può avere vari 
tipi di apprendimento: \emph{Supervisionato, Semi-Supervisionato, Non-Supervisionato} 
e con \emph{Rinforzo}. La scelta di quale usare dipende dalla tipologia della rete e dal 
suo campo di applicazione.

\subsection{Apprendimento Supervisionato}
In questa tipologia di apprendimento, l’input fornito alla rete contiene una serie di 
dati etichettati. L’apprendimento supervisionato è solitamente utilizzato sia nel 
conteso della classificazione, dove  si vuole mappare le etichette di input a quelle 
di output, che nel contesto della regressione, dove si mira a mappare l’input a un 
output continuo. La corretta associazione comporta una buona generalizzazione 
da parte del modello. L’apprendimento migliora grazie ad una continua variazione 
dei pesi. Questo tipo di apprendimento è svolto utilizzando la tecnica della 
\emph{Back-Propagation}. La complessità di questo tipo di apprendimento deriva dalla 
quantità di dati presenti nel training set. Affinché la rete riesca a generalizzare al 
meglio, il training set dev’essere composto da un numero di esempi adeguato. La 
giusta quantità di esempi è utile a prevenire spiacevoli situazioni di underfitting o 
di overfitting della rete.

\subsection{Apprendimento Non-Supervisionato}
Quando una rete neurale è sottoposta ad un simile apprendimento, questa riceve 
in input dei dati privi di etichettatura o non strutturati. Lo scopo della rete, 
o del modello, è quello di estrarne una rappresentazione e creare dei cluster 
rappresentativi. Ci sono delle tecniche a supporto di questa tipologia di apprendimento, 
una fra queste è la riduzione della dimensionalità che è applicata in fase 
di pre-elaborazione delle features avente l’obiettivo di eliminare il rumore dai dati 
quando questi sono presenti in grandi quantità. 

\subsection{Apprendimento Semi-Supervisionato}
Un set di input composto da dati etichettati e non, costituisce un sistema di apprendimento 
semi-supervisionato. Questa tipologia di apprendimento rappresenta 
un sistema che si interpone tra i due precedentemente spiegati. I modelli che fanno 
uso di questo approccio di solito utilizzano una piccola quantità di dati etichettati 
e una grande quantità di dati non etichettati. Tale apprendimento porta alla 
creazione di un modello più flessibile rispetto a quello ottenuto dall’apprendimento 
supervisionato.

\subsection{Apprendimento con Rinforzo}
L’ultimo tipo di apprendimento automatico è chiamato Apprendimento con 
Rinforzo. Il suo scopo è quello di costruire un sistema, comunemente chiamato 
\emph{agente}, che abbia l’obiettivo di migliorare le sue performance interagendo con 
l’ambiente che lo circonda. Il miglioramento dell’intero sistema avviene mediante 
dei feedback chiamati appunto rinforzi. Quest’ultimi non hanno nulla a che fare 
con etichette o valori di verità, ma rappresentano un livello di qualità delle azioni 
intraprese dal sistema. Pertanto, differentemente da un sistema supervisionato, 
non ci sono mappature tra l’input e l’output.

\subsection{Algoritmo di Back-Propagation}\label{BP}
Il termine \emph{Back-Propagation} è stato introdotto una prima volta quando si è 
trattato l’argomento dell’apprendimento Supervisionato. Una prima definizione 
del termine venne data nel 1986 in \cite{03}. L’algoritmo di Back-Propagation agisce 
durante la fase di training del modello, che a sua volta si suddivide in due fasi:
\begin{enumerate}
    \item \emph{Fase in avanti (forward)}: i dati si propagavano dai neuroni di input fino 
    a raggiungere i neuroni di output. I pesi sono fissati e i cambiamenti sono 
    limitati.
    \begin{figure}[H]
        \centering
        \includegraphics[width = \linewidth]{feedforward.png}
        \centering
        \caption{Esempio fase di propagazone dei dati in avanti di una rete \emph{feedforward}.}
        \label{feedforward net}
    \end{figure}
    \item \emph{Fase in indietro (backward)}:  si confronta il risultato ottenuto, da un primo 
    step in avanti, con il risultato atteso. Tale valore rappresenterà l’errore 
    commesso, descritto in precedenza dalla funzione di errore $E$ (\ref{error function}). A questo 
    punto, tale errore si propagherà indietro nella rete. Questo meccanismo è 
    utile ad adeguare i vari pesi presenti nella rete affinché le prossime iterazioni 
    diano un errore relativamente basso (caso ottimale in cui l’output stimato è 
    simile all’output desiderato).
    \begin{figure}[H]
        \centering
        \includegraphics[width = 0.7\linewidth]{BP.png}
        \centering
        \caption{Esempio fase di retropropagazione degli errori.}
        \label{BP error}
    \end{figure}
\end{enumerate}
Sappiamo che una minima variazione ai pesi e al bias comporta allo stesso modo 
una variazione della funzione di errore E. Tralasciando un’attimo il bias, il discorso 
che segue è incentrato sulla gestione dei pesi. L’algoritmo di Back-propagation 
applica una correzione chiamata {\bfseries{Delta Rule ($\Delta{W_{ji}}$)}}  ad ogni peso $w_{ji}$, andando 
a calcolare, tramite la regola della \emph{Chain Rule} \ref{chain rule}, la derivata parziale della funzione 
di errore $E$, rispetto alla derivata della parziale del peso $w_{ji}$ in considerazione.
\begin{equation}\label{chain rule}
    \frac{\partial E}{\partial w_{ji}} = \frac{\partial E}{\partial e_{j}} 
    \frac{\partial e_{j}}{\partial y_{j}}
    \frac{\partial y_{j}}{\partial a_{j}}
    \frac{\partial a_{j}}{\partial w_{ji}}
\end{equation}
dove:
\begin{equation}\label{derivation solved 1}
    \frac{\partial E}{\partial e_{j}} = e_j
\end{equation}
\begin{equation}\label{derivation solved 2}
    \frac{\partial e_{j}}{\partial y_{j}} = -1
\end{equation}
\begin{equation}\label{derivation solved 3}
    \frac{\partial y_{j}}{\partial a_{j}} = \varphi_j^{'}(a_j)
\end{equation}
\begin{equation}\label{derivation solved 4}
    \frac{\partial a_{j}}{\partial w_{ji}} = y_i
\end{equation}
Ogni elemento definito dalla chain rule sarà utile, oltre che a formare il vettore 
del gradiente $\nabla{E}$ (\ref{gradient vector}), a determinare la direzione di ricerca all’interno dello spazio 
dei pesi, per un singolo peso $w_{ji}$. Questa operazione, in letteratura, è nominata 
come \emph{“Discesa del gradiente”}. Ricapitolando, la (\ref{chain rule}) diventa:
\begin{equation}\label{chain rule update}
    \frac{\partial E}{\partial w_{ji}} = -e_j\varphi_j^{'}(a_j)y_i
\end{equation}
Giunti a questo punto, è possibile calcolare la \emph{Delta Rule} ($\Delta{W_{ji}}$) sul peso $w_{ji}$:
\begin{equation}\label{delta rule 1}
    \Delta{W_{ji}} = -\alpha \frac{\partial E}{\partial w_{ji}}
\end{equation}
dove $-\alpha$ simboleggia un parametro, chiamata \emph{Learning Rate}, che rappresenta 
un indicatore di velocità di apprendimento della rete. Il segno negativo è utile 
per agevolare la discesa del gradiente affinché si riduca il valore della funzione di
errore $E$. Dalla (\ref{delta rule 1}) possiamo definire il \emph{gradiente locale $\delta_j$}:
\begin{eqnarray}\label{local gradient of output layer}
    \delta_j & = & \frac{\partial E}{\partial a_{j}} \nonumber \\
             & = & \frac{\partial E}{\partial e_{j}} \frac{\partial e_{j}}{\partial y_{j}} \frac{\partial y_{j}}{\partial a_{j}} \nonumber \\
             & = & e_j\varphi_j^{'}(a_j)
\end{eqnarray}
Il gradiente locale sta ad indicare i cambiamenti richiesti nei pesi e questo dipende 
dalla tipologia di neurone:
\begin{enumerate}
    \item Se il neurone \emph{j} è un neurone di output, $\delta_j$ è uguale al prodotto della derivata 
    $\varphi_j^{'}(a_j)$ e il singolo errore $e_{j}$, entrambi associati al neurone $j$ (\ref{local gradient of output layer});
    \item Se il neurone \emph{j} è un neurone nascosto, $\delta_j$ è uguale al prodotto tra la derivata 
    $\varphi_j^{'}(a_j)$ e la sommatoria dei vari $\delta$ calcolati sui neuroni posti nel layer nascosto, 
    o nel layer di output, connessi al neurone \emph{j} (\ref{local gradient of hidden neuron}).
    \begin{equation}\label{local gradient of hidden neuron}
        \delta_j = \varphi_j^{'}(a_j)\sum_{k}\delta_kw_{kj}
    \end{equation}
\end{enumerate}
Sostituendo in (\ref{chain rule update}) la (\ref{local gradient of output layer}), possiamo modificare la (\ref{delta rule 1}) in:
\begin{equation}\label{delta rule 2}
    \Delta{W_{ji}} = -\alpha \delta_jy_i 
\end{equation}
Infine, grazie alla definizione della \emph{Delta Rule}, nell’iterazione $n+1$ sarà possibile 
aggiornare il peso $w_{ji}$ in questione, rispetto all’iterazione $n$ precedente:
\begin{equation}\label{weight change}
    w_{ji}(n+1) = w_{ji}(n)+\Delta{w_{ji}(n)}
\end{equation}
In precedenza, si era preferito mettere da parte il concetto di bias per concentrarci 
maggiormente sui pesi. Essendo la funzione di errore sensibile anche al cambiamento 
del bias, l’algoritmo di back-propagation ha lo scopo di aggiornare anche i 
vari bias esistenti integrando, nel vettore gradiente $\nabla{E}$, le derivate parziali della 
funzione di Errore rispetto al bias $b$:
\begin{equation}\label{gradient vector with bias}
    \nabla{E}[\vec{b}]\equiv\left[\frac{\partial E}{\partial b_{0}}, \frac{\partial E}{\partial b_{1}}, \dots, \frac{\partial E}{\partial b_{j}}\right]
\end{equation}
I successivi calcoli sono identici a quelli dell’aggiornamento dei pesi. Il processo 
di back-propagation avviene in maniera iterativa e si ferma quando vengono 
soddisfatte le seguenti caratteristiche:
\begin{enumerate}
    \item Raggiungimento del numero massimo di epoche;
    \item L’errore è più basso della soglia;
    \item Non vi è nessun cambiamento dei pesi.
\end{enumerate}

\section{Tipologie di reti neurali}
Esistono diverse tipologie di reti neurali, tra queste abbiamo:
\begin{itemize}
    \item \emph{Reti neurali feed forward (FNN)}
    \item \emph{Reti neurali ricorrenti (RNN)}
    \item \emph{Reti profonde (DNN)}
    \item \emph{Reti convoluzionali (CNN)}
\end{itemize}
Nel seguente elaborato verranno trattate solamente le reti neurali convoluzionali 
ma, prima di introdurle, al fine di capire il loro funzionamento, è necessario 
introdurre prima le reti neurali feed-forward, dette anche reti neurali a catena 
aperta.

\subsection{Reti neurali Feed-Forward}
Per facilitare la comprensione del funzionamento di una comune rete neurale, 
si potrebbe partire dallo studio del comportamento di una feed-forward neural 
network. Questa tipologia di rete può essere vista come una funzione matematica 
non lineare capace di trasformare dei dati di input $x=(x_1, \dots, x_m)$, in dati in 
output $y=(y_{j1}, \dots, y_{jn})$. Quello che accade è quindi una transizione delle variabili 
indipendenti ($X_j$) in variabili dipendenti($Y_j$). Possiamo quindi considerare la 
rete come una funzione nella forma $y = y(x;w)$, dove $y$ sta a rappresentare una funzione di $x$ 
e che a sua volta è parametrizzata da $w$. In una rete feed-forward, il 
processo di calcolo è unilaterale, ovvero procede solamente in avanti, raggiungendo 
l’ultimo layer. Rispetto a una rete semplice, una rete feedforward può essere 
composta da più layer nascosti in cui vi sono più neuroni nascosti. L’aggiunta 
di un numero sostanziale di layer nascosti può aiutare ad estrarre statistiche di 
ordine superiore dai dati di input. Secondo \cite{04}, la presenza di più connessioni 
sinaptiche tra i neuroni, provoca una maggiore iterazione tra questi che a sua 
volta aiuta alla rete a raggiungere una prospettiva globale. Una rete che ha più di 
un layer nascosto, e quindi probabilmente con un alto numero di connessioni, in 
gergo è chiamata rete \emph{fully connected}. Al contrario, se alcuni collegamenti sono 
assenti, tale tipologia di rete viene chiamata \emph{partially connected}.

\subsection{Reti neurali Convoluzionali}
Una rete neurale convoluzionale (CNN o ConvNet) è una tipologia di rete feed-
forward che si sta affermando come stato dell’arte per una svariata gamma di 
applicazioni nel campo della computer vision. Una loro prima diffusione avvenne 
negli anni ’90 grazie a uno studio di LeCun e Boser \cite{NIPS1989_53c3bce6}. L’architettura delle CNN 
si distinguono grazie al numero di layer presenti.  La loro particolarità sta nel 
rilevare i tratti più rilevanti e di apprendere i pattern, il tutto con un alto grado di 
invariata rispetto a traslazione, ridimensionamento, inclinazione e altre forme di 
distorsione. I primi strati hanno il compito di estrarre le features di basso livello, 
come per esempio i bordi o i blob, al contrario, gli ultimi strati hanno lo scopo di 
estrarre le features di alto livello tipo i contorni, classificazione, riconoscimento 
etc. All’interno di una rete convoluzionale possiamo riconoscere due tipologie di 
neuroni:
\begin{itemize}
    \item \emph{Neuroni di elaborazione}: hanno lo scopo di elaborare una sezione specifica 
    dell’immagine, comunemente chiamata campo ricettivo, utilizzando 
    un’operazione di \emph{convoluzione};
    \item \emph{Neuroni di aggregazione}: hanno lo scopo di eseguire un'operazione di \emph{pooling}.
\end{itemize}
I neuroni contenuti in uno strato adibito alla convoluzione, e quelli completamente 
connessi, dispongono di funzioni di attivazione e di pesi, quest’ultimi sottoposti a 
processo di aggiornamento durante la fase di apprendimento. Per quanto riguarda 
gli strati di pooling, questi non dispongo di alcun tipi di peso. Riassumendo, 
le operazioni svolte dalle CNN sono essenzialmente quattro: {\bfseries{Convoluzione}}, {\bfseries{Non 
Linearità (ReLU)}}, {\bfseries{Pooling (o Sub Sampling)}} e {\bfseries{Classificazione}} (nei layer 
fully connected). 
\begin{figure}[H]
    \centering
    \includegraphics[width = \linewidth]{cnn complete.png}
    \centering
    \caption{Esempio di architettura di una rete CNN.}
    \label{CNN complete}
\end{figure}

\subsubsection{Convoluzione}
Lo scopo del layer di convoluzione è quello di attuare un’operazione di {\bfseries{feature 
extraction}}. In questa fase ogni neurone prende in input un campo ricettivo 
locale del layer precedente e da qui ne estrae le feature locali. Un filtro, che in 
gergo prende il nome di {\bfseries{\emph{kernel}}}, trasla sull’immagine originale con l’intenzione di 
creare una feature map mediante moltiplicazione tra i valori presenti nel filtro, 
corrispondenti ai pesi, e la regione dell’immagine in cui si trova. Di seguito, i 
valori di ogni feature map sono calcolati tramite la seguente formula:
\begin{equation}\label{sum convolution}
    G=[m,n] = (f*h)[m,n] = \sum_j\sum_kh[j,k]f[m-j,n-k]
\end{equation}
dove:
\begin{itemize}
    \item $f$: immagine in input
    \item $h$: kernel
    \item $m,n$: indici di riga e colonna.
\end{itemize}
\begin{figure}[H]
    \centering
    \includegraphics[width = 0.8\linewidth]{convolution.png}
    \centering
    \caption{Esempio di dimensione filter e di campo ricettivo.}
    \label{filter dimension}
\end{figure}
Dopo aver posizionato il filtro su un campo ricettivo, vero preso ogni valore dal 
kernel e moltiplicato con i valori corrispondenti al campo ricettivo dell’immagine. 
Successivamente, il valore risultante verrà inserito nella giusta posizione della 
feature map.
Il numero di feature map sarà uguale al numero di filtri applicato sull’immagine. 
La generazione di ogni feature map dipende da quattro tipi di parametri, detti 
\emph{iperparametri}:
\begin{enumerate}
    \item \emph{Dimensione dei filtri}: pari alla dimensione del campo ricettivo ovvero della 
    porzione dell’immagine che si vuole analizzare;
    
    \item \emph{Profondità (depth)}: numero di filtri “$N$” usati durante la convoluzione 
    ($H \times W \times N$). Ogni filtro produrrà una propria feature map;
    \begin{figure}[H]
        \centering
        \includegraphics[width = 0.5\linewidth]{filter.png}
        \centering
        \caption{Esempio di profondità composto da più filtri.}
        \label{filters depth}
    \end{figure}
    \item \emph{Passo (stride)}: rappresenta il numero di pixel su cui viene fatto traslare il 
    kernel ogni volta che esegue una moltiplicazione. Per ottenere una buona 
    feature map è consigliato avere un valore di stride relativamente basso;
    \begin{figure}[H]
        \centering
        \includegraphics[width = \linewidth]{stride.png}
        \centering
        \caption{Esempio convoluzione con kernel=3x3 e stride=1.}
        \label{stride}
    \end{figure}
    \item \emph{Riempimento (Padding)}: affinché venga generata una corretta feature map 
    di dimensioni pari ($padding=1$) o maggiore ($padding>1$) a quella dell’immagine 
    di partenza, la matrice dell’immagine deve essere riempita di valori uguali, 
    esempio di zeri, presso le sue estremità.
    \begin{figure}[H]
        \centering
        \includegraphics[width = \linewidth]{padding and stride.png}
        \centering
        \caption{Esempio convoluzione con kernel=4x, padding=2 e stride=1.}
        \label{padding e stride}
    \end{figure}
\end{enumerate}
La scelta degli iperparametri non è standard ma dipende maggiormente dalla 
tipologia dei dati a disposizione.

\subsubsection{Rectified Linear Unit (ReLU)}
Ogni feature map, dopo la convoluzione, è composta da dei valori positivi e negativi. 
Come brevemente accennato in (\ref{Reti neurali}), esistono varie funzioni di attivazione che, in 
base all’input ricevuto, decidono se attivare o disattivare un neurone. La 
funzione di attivazione maggiormente usata è la ReLU (Rectified Linear Unit). 
Questa funzione esegue delle operazioni non lineari ponendo a zero tutti i valori 
negativi e lasciando invariati i valori positivi, generando in questo modo delle 
attivazioni sparse.  L’operazione prende il nome di element-wise su tutti i pixel. 
L’implementazione di questa funzione, rispetto alle sue concorrenti, è utile ad accelerare 
il processo di apprendimento (backpropagation) del modello semplificando 
le operazioni nei vari layer.
\begin{figure}[H]
    \centering
    \includegraphics[width = 0.8\linewidth]{relu.png}
    \centering
    \caption{Esempio funzione di attivazione ReLU sui valori di una feature map.}
    \label{relu}
\end{figure}
Rispetto alla sigmoide, la funzione ReLU pone a zero la derivata di un numero 
negativo, mentre per i numeri positivi la derivata è uguale a uno evitando la 
saturazione del gradiente.

\subsubsection{Pooling}

